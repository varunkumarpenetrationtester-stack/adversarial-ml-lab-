# Adversarial ML Attack & Defense Lab

This project demonstrates how machine learning models used in security systems
can be attacked using adversarial techniques and how simple defenses can reduce risk.

## Attacks Demonstrated
- Data Poisoning (training-time attack)
- Evasion Attacks (inference-time manipulation)

## Defenses Demonstrated
- Data Sanitization
- Confidence-based Manual Review

## Real-World Use Cases
- SOC analyst training
- AI security awareness
- ML pipeline hardening
- Adversarial ML research

## Tech Stack
- Python
- Streamlit
- scikit-learn

⚠️ This project is for educational and research purposes only.
